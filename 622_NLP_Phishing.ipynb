{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTPzAvSim2WW",
        "outputId": "ce582b9b-440f-4300-cf91-0a6f9b8fa77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1 0]\n",
            " [0 2]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n",
            "\n",
            "Top Spam/Phish Indicators:\n",
            "['link', 'account', 'password', 'iphone clicking', 'clicking link', 'clicking', 'free iphone', 'free', 'iphone', 'win', 'win free', 'offer', 'offer buy', 'time', 'time offer', '50 discount', '50', 'buy', 'buy 50', 'limited time']\n",
            "\n",
            "Top Ham Indicators:\n",
            "['attached', 'project', 'let', 'invoice attached', 'invoice', 'attached review', 'review', 'deadline', 'reminder', 'reminder submit', 'submit', 'submit assignment', 'assignment', 'assignment deadline', 'completed', 'completed successfully', 'modules', 'project update', 'modules completed', 'successfully']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Load data\n",
        "# ---------------------------\n",
        "# Expecting a CSV with columns: text, label\n",
        "# label: 1=spam/phish, 0=ham\n",
        "df = pd.read_csv(\"emails.csv\")  # <-- you will create this from corpus\n",
        "df = df.dropna(subset=[\"text\", \"label\"])\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Clean text\n",
        "# ---------------------------\n",
        "def clean_email(text: str) -> str:\n",
        "    text = str(text)\n",
        "    text = re.sub(r\"<[^>]+>\", \" \", text)          # remove HTML\n",
        "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" URL \", text)  # replace links\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text.lower()\n",
        "\n",
        "df[\"clean_text\"] = df[\"text\"].apply(clean_email)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"clean_text\"], df[\"label\"],\n",
        "    test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 3) TF-IDF vectorization\n",
        "# ---------------------------\n",
        "tfidf = TfidfVectorizer(\n",
        "    stop_words=\"english\",\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=30000\n",
        ")\n",
        "X_train_vec = tfidf.fit_transform(X_train)\n",
        "X_test_vec = tfidf.transform(X_test)\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Model\n",
        "# ---------------------------\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Evaluation\n",
        "# ---------------------------\n",
        "pred = model.predict(X_test_vec)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, pred))\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Top words (interpretability)\n",
        "# ---------------------------\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "coefs = model.coef_[0]\n",
        "\n",
        "top_spam = coefs.argsort()[-20:][::-1]\n",
        "top_ham = coefs.argsort()[:20]\n",
        "\n",
        "print(\"\\nTop Spam/Phish Indicators:\")\n",
        "print([feature_names[i] for i in top_spam])\n",
        "\n",
        "print(\"\\nTop Ham Indicators:\")\n",
        "print([feature_names[i] for i in top_ham])\n"
      ]
    }
  ]
}